% Chapter 2 of the Thesis Template File
%   which includes bibliographic references.

\Sexpr{knitr::set_parent('../thesis.Rnw')}
\graphicspath{{Images/chapter2/}{../Images/chapter2/}}

<<ch2-setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE, include=FALSE>>=
options(replace.assign=TRUE,width=70,scipen=3)
require(knitr)

wd <- getwd()
# Set paths for everything for compiling subdocument
if(!"Body" %in% list.files()){
  opts_chunk$set(fig.path='figure/chapter2/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, root.dir="../", message=F, warning=F, error=F)
  datadir <- "../data/chapter2/"
  imgdir <- "../figure/chapter2/"
} else {
  opts_chunk$set(fig.path='figure/chapter2/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE, message=F, warning=F, error=F)
  datadir <- "data/chapter2/"
  imgdir <- "figure/chapter2/"
}
@
\chapter{DATA AND METHODS}

\section{Data}

\subsection{\svp{Geometric} Class Characteristics}

Class characteristics, as defined in \autoref{sec:class-chars-desc}, are characteristics which can be used to exclude shoes from a match at a crime scene, but cannot be  used for individualized matching because they are shared by many shoes. A sufficiently well-defined set of characteristics can separate shoes into make and model categories \citep{grossVariabilitySignificanceClass2013}. \citet{grossVariabilitySignificanceClass2013} define geometric features such as circle/oval, crepe, herringbone, hexagon, parallel lines, logo/lettering/numbering, perimeter lugs, star, and other. Working from these categories, we assembled a set of categories which were more suited to recognition by convolutional neural networks, as some of the definitions used in Gross require spatial context which is not preserved during the labeling process (for example, lugs are required to be on the perimeter of the shoe). \autoref{tab:class-char-examples} shows three examples of each class.

\svp{\begin{description}
\item [Bowtie] Bowtie shapes are roughly quadrilateral, with two opposite concave faces. The remaining two faces can be convex or straight, and the concave faces may have straight portions, so long as there is a concave region. Using this definition, shapes such as butterflies are included as bowties.
\item [Chevron] Chevron shapes include repeating parallel lines as well as individual ``v" shapes. They may be angular but can also be curved.
\item [Circle] Circles include ellipses and ovals; they must be round.
\item [Line] Lines are repeated and parallel; a more general definition of a line would be difficult to differentiate from many other patterns. Lines can be mildly curved.
\item [Polygon] Polygons are defined in this standard to have more than 4 sides. They include pentagons, hexagons, and octagons.
\item [Quadrilateral] Quadrilaterals (quads) have four sides. They may have rounded or square corners.
\item [Star] Stars are any shape with alternating concave and convex regions, or lines which emanate from a central point. ``X" and ``+" shapes are also classified as stars.
\item [Text] Text is any shape which would be identified as text by a reasonable human. In most cases, the text on our images is made up of latin alphabet charcters; the model will likely not recognize text in other scripts at this point (but could be trained with text in other scripts if such training images could be obtained). Text frequently includes component shapes such as circles; where these shapes are clearly defined, they are labeled as well, as the model does not have the ability at this time to impose the necessary context on images to differentiate an ``o" from a circle.
\item [Triangle] Triangles are any three-sided figure. Like quadrilaterals, they can have rounded corners. In some cases, it is difficult to distinguish between a trapezoidal shape and a triangle when rounded corners are involved.
\item [Other] Other features which were marked include logos, various textures (including crepe, stippling, etc.), and smooth regions with no discernible features. These regions are grouped and provide additional information - that none of the previous nine categories are present.
\end{description}
}

Defining categories this way does not remove all ambiguities. The best example lies in considering text. The letter "v" can easily be considered a chevron, and the letter "o" is clearly a circle. However, text is also an important category to encompass the variety of ways text appears on footwear outsoles, and it is not necessarily helpful (or possible) to try to categorize every shape in text into another category. Many of the ambiguities that arise can be solved by applying multiple labels to an image, but some shapes also do not fit into any categories. Applying comprehensive and consistent labels to difficult or ambiguous shapes is the most difficult part of this process.

\begin{table}
\centering

\setlength\tabcolsep{1mm}
\begin{tabular}{rccl}
     Bowtie & \raisebox{-.5\height}{\includegraphics[width=.3\linewidth]{class_examples/bowtie_examples.png}} &
     \raisebox{-.5\height}{\includegraphics[width=.3\linewidth]{class_examples/chevron_examples.png}} & Chevron \vspace{1mm}\\
     Circle & \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/circle_examples.png}} &
     \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/line_examples.png}} & Line  \vspace{1mm}\\
     Polygon & \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/polygon_examples.png}} &
     \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/quad_examples.png}} & Quad  \vspace{1mm}\\
     Star & \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/star_examples.png}} &
     \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/text_examples.png}} & Text  \vspace{1mm}\\
     Triangle & \raisebox{-.5\height}{\includegraphics[width=0.3\linewidth]{class_examples/triangle_examples.png}} &
      \raisebox{-.5\height}{} & \\
\end{tabular}
\caption[Geometric elements]{Geometric Elements. Categories modified from \cite{grossVariabilitySignificanceClass2013}.}\label{tab:class-char-examples}
\end{table}

\subsection{Data Collection}

Thousands of outsole images were web-scraped from Zappos.com, a large online shoe retailer. These images were then uploaded for use in a tool called LabelMe \mt{(cite)}, a labeling/annotating interface which allows users to easily select and label regions of an image. To date, about [2,200] shoes have been labeled, yielding about [24,000] multi-label images. *Image processing?* \svp{R code, using the imager package and spatial packages - check code to get a good list}

\mt{Should "Image Processing" be a new section? I'm thinking about the scripts that take the images from LabelMe to the data folders. It's also relevant for the point about not maintaining aspect ratio that you added in the Data Characteristics section below.}

\mt{Is the 60/20/20 split a data characteristic for Ch 2 or a Training Parameters thing for ch3?} 

To train the CNN, data was split such that 60\% went to training, and 20\% each to validation and test data.


\subsection{Data Characteristics}

-Quantities, examples, etc
\svp{Show histogram of class distribution}
\svp{Talk about ``other" - it's necessary to train the model on null data as well}

\svp{256x256 images, aspect ratio not maintained (but efforts to label with relatively square labels). }

\svp{One thing I need to examine is what happens if we use histogram equalization to modify the images before augmentation. I did a bit of that for presentation images and it changed the output probabilities a lot... which suggests it may help with images that don't have even color balance.}

\subsection{Augmentation}
\mt{Augmentation includes crop, zoom, skew, rotate, and color}

\section{VGG16}

\textbf{VGG16 Architecture}
The main difference between different CNNs is their structure, meaning the number of layers they contain and the pattern those layers are in. In our research, we have tested a few pre-trained CNNs, and we are currently using VGG16. Developed by Oxford's Visual Graphics Group, VGG16 has 16 "functional" (i.e., convolutional and densely connected) layers and 5 max-pooling layers, which function more to alter the structure of the information at each step.

%In the case of VGG16, early convolutional layers contain 64 features that primarily detect colors and edge patterns. Later convolutional layers of VGG16, in contrast, contain 512 filters that represent much more complex features, like animal fur patterns or distinct bird heads.

%VGG16 follows groups of 2 or 3 convolutional layers with a max-pooling layer, which ultimately takes in initial feature maps of size 224x224 and ends with maps of size 7x7.

\includegraphics[width = \linewidth]{vgg16-shoe-nolabel.png}

\svp{Show VGG16 architecture image ... and talk through the image dimension changes.}

\svp{Contrast VGG16 structure with ResNet - \href{https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624}{one source}, explain VGG16 is simpler, so we can more easily explain it and produce diagnostic images.}



