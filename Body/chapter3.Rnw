% Chapter 3: Results

\Sexpr{knitr::set_parent('../thesis.Rnw')}
\graphicspath{{Images/chapter3/}}
\graphicspath{{figure/chapter3/}}

<<ch3-setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE, include=FALSE>>=
options(replace.assign = TRUE, width = 70, scipen = 3)
require(knitr)

wd <- getwd()
# Set paths for everything for compiling subdocument
if (!"Body" %in% list.files()) {
  opts_chunk$set(fig.path = 'figure/chapter3/fig-', cache.path = 'cache/',
                 fig.align = 'center', fig.width = 5, fig.height = 5,
                 fig.show = 'hold', par = TRUE, cache = TRUE,
                 concordance = TRUE, autodep = TRUE, root.dir = "../",
                 message = F, warning = F, error = F)
  datadir <- "../data/chapter3/"
  imgdir <- "../figure/chapter3/"
  codedir <- "../code/"
  modeldir <- "../model/"
} else {
  opts_chunk$set(fig.path = 'figure/chapter3/fig-', cache.path = 'cache/',
                 fig.align = 'center', fig.width = 5, fig.height = 5,
                 fig.show = 'hold', par = TRUE, cache = TRUE,
                 concordance = TRUE, autodep = TRUE,
                 message = F, warning = F, error = F)
  datadir <- "data/chapter3/"
  imgdir <- "figure/chapter3/"
  codedir <- "code/"
  modeldir <- "model/"
}
@


\chapter{RESULTS}\label{ch:results}

<<model-setup2, include = T, cache = F>>=
library(magrittr)
library(tidyverse)
library(ggplot2)
library(keras)
mytheme <- theme_bw() #+
  # theme(panel.grid.major = element_line(color = "grey50"),
  #       panel.grid.minor = element_line(color = "grey60"))

theme_set(mytheme)
knitr::opts_chunk$set(echo = FALSE, message = F, warning = F, cache = T, dpi = 300, dev = 'png')

source(file.path(codedir, "Generate_Model_Images.R"))

# Load model
model_path <- file.path(modeldir, "TrainedModels")

newest_model <- get_newest(dir = model_path, pattern = "weights.h5")
newest_data_file <- file.path(modeldir, "RProcessedImages",
                              newest_model$process_dir, "cropped_photos.Rdata")

model_dir <- newest_model$path
load(list.files(model_dir, "-history.Rdata", full.names = T)[1])
load(file.path(get_newest()$path, get_newest(pattern = "\\d.Rdata")$base_file))
model_wts_file <- file.path(newest_model$path, newest_model$base_file)
loaded_model <- set_weights(model_wts_file)
@

\section{Model Training}
<<training-accuracy, fig.width = 7.5, fig.height = 5, out.width = ".75\\textwidth", fig.cap = "Training and validation accuracy and loss for each epoch of the fitting process. Training and validation accuracy reach 89.5\\% around epoch 9. After that point, validation loss remains the same and training loss decreases slightly, while validation accuracy increases more slowly than training accuracy.", fig.scap = "Training and validation accuracy and loss during each epoch.", fig.pos = 'h'>>=
data.frame(history$metrics) %>%
  mutate(epoch = 1:n()) %>%
  gather(key = "measure", value = "value", -epoch) %>%
  mutate(Type = ifelse(str_detect(measure, "val"), "Validation", "Training"),
         measure = ifelse(str_detect(measure, "acc"), "Accuracy", "Loss")) %>%
  # bind_rows(tibble(epoch = NA, value =  .6, measure = "Accuracy", Type = "Validation")) %>%
  # bind_rows(tibble(epoch = NA, value =  .33, measure = "Loss", Type = "Validation")) %>%
  ggplot(aes(x = epoch, y = value, color = Type)) +
  geom_point() +
  geom_smooth(se = F) +
  facet_grid(measure~., scales = "free_y", switch = "both") +
  theme_bw() +
  scale_y_continuous("") +
  scale_x_continuous("Epoch") +
  ggtitle("CoNNOR Training Performance") + mytheme +
  theme(axis.title.y = element_blank(), legend.position = c(1, .5), 
        legend.justification = c(1.03, -0.05), 
        legend.background = element_rect(fill = "white"))
@

\autoref{fig:training-accuracy} shows the training and validation accuracy and loss at each epoch of the fitting process. Overfitting, or fitting a model which performs too well on the training data relative to the validation data, is seen when the validation loss starts to increase after reaching a global minimum; underfitting, on the other hand, may be suspected when the validation accuracy is still increasing toward the end of the fitting process. Neither of these outcomes appears in \autoref{fig:training-accuracy}, indicating that the model optimization process was halted at an appropriate epoch.

\FloatBarrier

\section{Model Accuracy}\label{ch3:model-accuracy}

\paragraph{ROC}

\autoref{fig:roc-code} shows the ROC curve for the full model, and \autoref{fig:auc-code} shows the curve for each class. The full model has an AUC of 0.88, and the AUC for individual classes ranges from 0.83 (for star and triangle) to 0.91 (for bowtie and text). While the class performances do vary slightly, each ROC curve is the same general shape and performs significantly better than random chance.

<<roc-code, fig.width = 5, fig.height = 5, out.width = ".5\\textwidth", fig.cap = "Whole model ROC Curve">>=
library(pROC)
pred_df <- as_tibble(preds) %>% gather(key = feature, value = value)
test_labs_df <- as_tibble(test_labs) %>% gather(key = feature, value = value)
whole_model_roc <- roc(test_labs_df$value, pred_df$value)

whole_model_roc_df <- tibble(tpr = whole_model_roc$sensitivities,
                             fpr = 1 - whole_model_roc$specificities,
                             thresholds = whole_model_roc$thresholds,
                             auc = whole_model_roc$auc[1]) %>%
  nest(tpr, fpr, thresholds, .key =  "roc_plot") %>%
  mutate(eer = purrr::map(roc_plot, eer))
ggplot() +
  geom_line(aes(x = fpr, y = tpr), data = unnest(whole_model_roc_df, roc_plot), size = 1.25) +
  geom_label(aes(x = 1, y = .07, label = sprintf("AUC: %0.2f", auc)), hjust = 1, vjust = -0.2, data = whole_model_roc_df) +
  geom_point(aes(x = fpr, y = tpr, color = "Equal Error Rate"), data = unnest(whole_model_roc_df, eer), size = 2) +
  scale_color_manual("", values = "black") +
  scale_x_continuous("False Positive Rate", breaks = c(0, .25, .5, .75, 1), labels = c("0.0", "", "0.5", "", "1.0")) +
  scale_y_continuous("True Positive Rate", breaks = c(0, .25, .5, .75, 1), labels = c("0.0", "", "0.5", "", "1.0")) +
  ggtitle("CoNNOR Test Set Performance (All Classes)") +
  coord_fixed() + mytheme +
  theme(legend.position = c(1, 0), legend.justification = c(1.01, -0.01), legend.title = element_blank(), legend.background = element_rect(fill = "white"))

@

<<auc-code, fig.width = 8, fig.height = 6, out.width = "\\textwidth", fig.cap = "Class-by-class ROC curves. AUC is area under the curve, a measure of overall model performance. Equal error rates are marked, indicating the position at which there is equal probability of a false positive or false negative error.", fig.scap = "Class-by-class ROC curves.">>=
aucs <- plot_onehot_roc(preds, test_labs, str_to_title(classes))
thresholds <- purrr::map_dbl(aucs$data$eer, ~.$thresholds)
aucs$data$thresholds <- thresholds

ggplot() +
  geom_line(aes(x = fpr, y = tpr), data = unnest(aucs$data, roc_plot), size = 1.25) +
  geom_label(aes(x = 1, y = 0, label = sprintf("AUC: %0.2f\nEER: %0.2f", auc, thresholds)), hjust = 1, vjust = -0.02, data = aucs$data) +
  geom_point(aes(x = fpr, y = tpr, color = "Equal Error\nRate (EER)"), data = unnest(aucs$data, eer), size = 2.5) +
  scale_color_manual("", values = "black") +
  facet_wrap(~class) +
  scale_x_continuous("False Positive Rate", breaks = c(0, .25, .5, .75, 1), labels = c("0.0", "", "0.5", "", "1.0")) +
  scale_y_continuous("True Positive Rate", breaks = c(0, .25, .5, .75, 1), labels = c("0.0", "", "0.5", "", "1.0")) +
  ggtitle("CoNNOR Test Set Performance") +
  facet_wrap(~class, nrow = 2) +
  coord_fixed() +
  theme(legend.position = c(1, 0), legend.justification = c(1, 0))
@

\FloatBarrier

\paragraph{Confusion Matrix}
As stated in \autoref{sec:model-eval}, a confusion matrix is a cross-tabulation of the labels assigned to an image and the labels predicted by the model. In a single-label problem, an image belongs to only one category and the model predicts only one label, so applying the wrong label is equivalent to failing to apply the correct label. Thus, every possible combination of true label and applied prediction is represented in the two-dimensional/traditional confusion matrix. Extending the confusion matrix to more complex problems requires additional considerations.

Although some efforts to generalize confusion matrices to multi-class problems do exist in the literature \citep{landgrebeEfficientMulticlassROC2008}, it appears that confusion matrices have not previously been applied to multi-label classification problems. Since a single image may belong to a combination of the $n$ categories, it is no longer true that a false positive and a false negative are equivalent (see \autoref{tab:error-3class-problem}). The confusion matrix presented in \autoref{fig:confusion_matrix} is like a traditional confusion matrix in that all values along the diagonal represent the proportion of true positives captured within each category. The off-diagonal values, however, are adjusted from the traditional method to remove the effect of any true positives from the calculation of false positive proportions. For example, to calculate the proportion of images that contain triangles but are being falsely labeled as containing quadrilaterals, any image that truly contains both triangles and quadrilaterals is removed before calculating the proportion of false quadrilateral labels.


<<confusion_matrix, fig.width = 9, fig.height = 8, out.width = "\\textwidth", fig.cap = "Confusion matrix, showing on the diagonal the full classification rate and on the off-diagonal, classification errors. Note that in multi-label images, correct off-diagonal labels have been excluded from the calculation of false positives.", fig.scap = "Confusion matrix, with correct and incorrect model classifications.", dpi = 600>>=
get_confusion_matrix(predictions = preds, classes = classes,
                     test_labels = test_labs, threshold = thresholds) %>%
  set_names(str_to_title(classes)) %>%
  ggcorrplot(., hc.order = F, outline.col = "white", lab = T) +
  scale_fill_gradient("Classification\nRate", low = "white",
                      high = "cornflowerblue", limits = c(0, 1)) +
  scale_x_discrete("Image Label") + scale_y_discrete("Prediction") +
  theme(axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14, angle = 90, vjust = 1)) +
  ggtitle("CoNNOR Multi-Class Confusion Matrix: Test Set Performance") +
  theme_bw() +
  theme(panel.grid.major = element_line(color = "grey50"),
        panel.grid.minor = element_line(color = "grey60")) +
  theme(plot.margin = grid::unit(c(0,0,0,0), "mm"),
        plot.background = element_rect(fill = "transparent", color = NA),
        plot.subtitle = element_blank(), plot.caption = element_blank(),
        panel.spacing = unit(c(0, 0, 0, 0), "mm"))
@

This modified confusion matrix preserves the ability to identify patterns in over- and under-predictions; for instance, in \autoref{fig:confusion_matrix}, it can be seen that quadrilaterals are overrepresented in the model predictions (the horizontal band indicates that quadrilaterals are predicted more often than they should be for every true label). We can also see that polygons, stars, and triangles are often are underpredicted relative to the images which actually contain these categories and produce a large number of false positive predictions into other categories (evidenced by the vertical bands in the confusion matrix).

\autoref{fig:confusion_matrix} shows the general weaknesses of the model, but does not tell us where to look as to \emph{why} the model is not performing appropriately. In \autoref{ch3:model-consistency} and \autoref{ch3:heatmap}, we use alternative visualizations to better understand the weaknesses of the model when applied to actual images used to train, test, and validate the model.

\section{Model Consistency}\label{ch3:model-consistency}
In order to examine the model's consistency, and whether it can successfully detect features across a variety of images, we will explore several case studies in this section, probing the model's strengths and weaknesses.

\subsection{General shape recognition}
\fix{Talk about Connor's ability to recognize different shapes successfully. Elaborate on image contrast issues - the pictures VGG16 was trained on were photos, and so are the images CoNNOR was trained on, but these are artifical photos where any color variation is due to the shoe, so it's definitely transferring to a different domain, and not always successfully.}

<<generic-chevron, fig.width = 11, fig.height = 11, out.width = "\\textwidth", fig.cap = "Most chevrons are correctly classified, though instances where two quadrilaterals make up a chevron are missed, and one low-contrast light sole has low probability across all 9 geometric figures, indicating that low color contrast may be an issue for CoNNOR.", fig.scap = "Features detected in images labeled `chevron'", dpi = 600>>=
chevron2 <- list.files(here::here("Images", "chapter3", "test-imgs", "generic-chevron"), full.names = T)
pred_prob_plot(chevron2, loaded_model)
@

<<generic-text-line, fig.width = 11, fig.height = 6, out.width = "\\textwidth", fig.cap = "A selection of images containing text and/or lines. Most images are correctly identified as containing text, though again there is some indication that low-contrast images are poorly recognized. In addition, text which occurs towards the boundaries of the labeled region may n ot be successfully identified by the model.", fig.scap = "Features detected in  images with `text' and/or `line' labels.", dpi = 600>>=
text_line <- list.files(here::here("Images", "chapter3", "test-imgs", "generic-text-line"), full.names = T)
pred_prob_plot(text_line, loaded_model)
@

<<generic-triangle, fig.width = 11, fig.height = 7, out.width = "\\textwidth", fig.cap = "A selection of images with triangles, including text logos. Many of the triangles are correctly detected, but there are again problems with low-contrast images and with recognition of the triangles in the top image.", fig.scap = "Features detected in  images containing triangles.", dpi = 600>>=
triangle <- list.files(here::here("Images", "chapter3", "test-imgs", "generic-triangle"), full.names = T)
pred_prob_plot(triangle, loaded_model)
@

\subsection{Recognition across colors}
In order to more fully  understand CoNNOR's strengths and weaknesses, we have identified several shapes which are consistently present in several different color patterns, either from the same shoe model, or from the same brand and very similar tread patterns. These cases allow for us to control the geometric patterns while varying the color patterns in a real context---we could vary the colors artificially, but this could induce additional artifacts due to the image manipulation process.

<<uggs, fig.width = 11, fig.height = 12, out.width = "\\textwidth", fig.cap = "UGG logos as found on many different shoes, without a defined circle outline. The model predictions are relatively consistent, but detection of the circle and text elements vary based on image contrast and color.", fig.scap = "Features detected in the UGG shoe logo across different shoe models", dpi = 600>>=
uggs <- list.files(here::here("Images", "chapter3", "test-imgs", "ugg-star-logo"), full.names = T)
pred_prob_plot(uggs, loaded_model)
@

<<uggs-with-circle, fig.width = 11, fig.height = 9, out.width = "\\textwidth", fig.cap = "UGG logos as found on many different shoes, with a defined circle outline. Again, the model predictions are relatively consistent, but now detection of the triangle and star elements vary based on image contrast and color.", fig.scap = "Features detected in the UGG shoe logo across different shoe models", dpi = 600>>=
uggs_circle <- list.files(here::here("Images", "chapter3", "test-imgs", "ugg-circle-star-logo"), full.names = T)
pred_prob_plot(uggs_circle, loaded_model)
@

<<nb_logo, fig.width = 11, fig.height = 11, out.width = "\\textwidth", fig.cap = "New Balance logos found on several different shoes; note that the model can sometimes detect the logo even with color/texture changes, but when the color pattern is of higher contrast than the logo, the model can no longer recognize the logo successfully.", fig.scap = "Features detected in the New Balance shoe logo across different shoe models.", dpi = 600>>=
nb_logo <- list.files(here::here("Images", "chapter3", "test-imgs", "nb-logo"), full.names = T)
pred_prob_plot(nb_logo, loaded_model)
@

<<nike, fig.width = 11, fig.height = 8, out.width = "\\textwidth", fig.cap = "A selection of images from the same shoe model across different colors. The bottom figure, which is of a black sole and has very little contrast, is poorly recognized by the model. The image immediately above it is an automatically color-adjusted version of the same image, which is classified consistent with the other images.", fig.scap = "Features detected in a rounded triangle across different color soles. ", dpi = 600>>=
# Leaving myself a note here -
# Fred's Imagemagick scripts - autotone
#  autotone -w -G a-black-2.jpg a-black-autotone.jpg (turn off white balance and gamma correction)
nike <- list.files(here::here("Images", "chapter3", "test-imgs", "nike-rounded-triangle"), full.names = T)
pred_prob_plot(nike, loaded_model, sort = F)
@

<<chevron, fig.width = 11, fig.height = 9, out.width = "\\textwidth", fig.cap = "A selection of images containing a specific chevron pattern from Adidas shoes, in a variety of colors. In the more homogeneous contrast situations presented here, features are detected across color patterns. ", fig.scap = "Features detected in a chevron pattern across different colors.", dpi = 600>>=
chevron <- list.files(here::here("Images", "chapter3", "test-imgs", "chevron-pattern"), full.names = T)
pred_prob_plot(chevron, loaded_model, sort = F)
@

In the more homogenous contrast situation shown in \autoref{fig:chevron}, the color variation does not produce large variations in the output probabilities - the darkest image has only slightly lower probability than the lightest images. 

\subsection{Contrast Adjustment}
In several of the model consistency case studies presented, color contrast was identified as a possible reason for poor feature identification. There are automatic ways to adjust the contrast of photos, enhancing our ability to notice details (and presumably, the model's ability to identify details as well).
<<auto-color-balance, fig.width = 11, fig.height = 10, out.width = "\\textwidth", fig.cap = "Images with low contrast from previous cases, with corresponding auto-adjusted color balance images. The color balanced images are on top of the corresponding low-contrast images. In most cases, auto color balancing increases the output class probabilities for relevant categories, though the chevron image at the bottom is strongly recognized as a bowtie instead of a chevron pattern.", fig.scap = "An examination of color balance and its affect on identified features.", dpi = 600>>=
lowcontrast <- list.files(here::here("Images", "chapter3", "test-imgs", "low-contrast"), full.names = T)
pred_prob_plot(lowcontrast, loaded_model, sort = F)
@

\FloatBarrier

\section{Model Diagnostics - Heatmaps}\label{ch3:heatmap}
<<setup-heatmap>>=
imgs <- list.files(here::here("Images", "chapter3", "heatmaps"), full.names = T)
@

<<generate-heatmaps, include = F>>=
calc_heatmap(imgs[which(grepl("chevron-circle", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

calc_heatmap(imgs[which(grepl("corks", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

calc_heatmap(imgs[which(grepl("quad-triangle-polygon", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

calc_heatmap(imgs[which(grepl("star-quad", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

calc_heatmap(imgs[which(grepl("text", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

calc_heatmap(imgs[which(grepl("bowtie-star", imgs))], loaded_model) %>% create_composite(save_file = T, outdir = imgdir)

heatmaps <- list.files(imgdir, pattern = "^heatmap")
@

<<chevron-circle-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("chevron-circle", heatmaps)])
@

<<corks-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("corks", heatmaps)])
@

<<quad-triangle-hexagon-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("chevron-circle", heatmaps)])
@

<<star-quad-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("star-quad", heatmaps)])
@


<<text-seychelles-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("text", heatmaps)])
@

<<bowtie-star-heatmap, eval = T, out.width = ".95\\textwidth", fig.width = 8, fig.height = 6>>=
knitr::include_graphics(heatmaps[grepl("bowtie", heatmaps)])
@

