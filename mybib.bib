@article{ANNasModelsofNeuralInfoProcessing,
	title = {Editorial: {Artificial} {Neural} {Networks} as {Models} of {Neural} {Information} {Processing}},
	volume = {11},
	issn = {1662-5188},
	shorttitle = {Editorial},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2017.00114/full},
	doi = {10.3389/fncom.2017.00114},
	abstract = {Editorial: Artificial Neural Networks as Models of Neural Information Processing},
	language = {English},
	urldate = {2019-01-16},
	journal = {Frontiers in Computational Neuroscience},
	author = {Gerven, Marcel van and Bohte, Sander},
	year = {2017},
	keywords = {artificial intelligence, computational neuroscience, neural networks, rate coding, spiking neural networks},
	file = {Full Text PDF:C\:\\Users\\Owner\\Zotero\\storage\\HCYDPRQS\\van Gerven and Bohte - 2017 - Editorial Artificial Neural Networks as Models of.pdf:application/pdf}
}


@article{grossVariabilitySignificanceClass2013,
  title = {The Variability and Significance of Class Characteristics in Footwear Impressions},
  volume = {63},
  number = {3},
  journal = {Journal of Forensic Identification},
  year = {2013},
  pages = {332},
  author = {Gross, Susan and Jeppesen, Dane and Neumann, Cedric},
  file = {/home/srvander/Zotero/storage/EC9IV5R5/Gross et al_2013_The variability and significance of class characteristics in footwear.pdf}
}

@article{hancockInterpretationShoeprintComparison2012,
  title = {The Interpretation of Shoeprint Comparison Class Correspondences},
  volume = {52},
  number = {4},
  journal = {Science and Justice},
  year = {2012},
  pages = {243--248},
  author = {Hancock, Sheida and Morgan-Smith, Rian and Buckleton, John},
  file = {/home/srvander/Zotero/storage/6ULEJZV5/Hancock et al_2012_The interpretation of shoeprint comparison class correspondences.pdf}
}

@inproceedings{pavlouAutomaticExtractionClassification2006,
  title = {Automatic Extraction and Classification of Footwear Patterns},
  booktitle = {International {{Conference}} on {{Intelligent Data Engineering}} and {{Automated Learning}}},
  publisher = {{Springer}},
  year = {2006},
  pages = {721--728},
  author = {Pavlou, Maria and Allinson, Nigel M},
  file = {/home/srvander/Zotero/storage/EBZL8VGE/Pavlou_Allinson_2006_Automatic extraction and classification of footwear patterns.pdf}
}


@article{vgg16,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {https://arxiv.org/abs/1409.1556},
	language = {en},
	urldate = {2018-10-16},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	file = {Simonyan_Zisserman_2014_Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:/home/srvander/Zotero/storage/ULPNXPMS/Simonyan_Zisserman_2014_Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:application/pdf;Snapshot:/home/srvander/Zotero/storage/XG4LXKA2/1409.html:text/html}
}
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{LabelMe,
 author = {Russell, Bryan C. and Torralba, Antonio and Murphy, Kevin P. and Freeman, William T.},
 title = {LabelMe: A Database and Web-Based Tool for Image Annotation},
 journal = {Int. J. Comput. Vision},
 issue_date = {May       2008},
 volume = {77},
 number = {1-3},
 month = may,
 year = {2008},
 issn = {0920-5691},
 pages = {157--173},
 numpages = {17},
 url = {http://dx.doi.org/10.1007/s11263-007-0090-8},
 doi = {10.1007/s11263-007-0090-8},
 acmid = {1345999},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Annotation tool, Database, Object detection, Object recognition},
} 


@techreport{papert_summer_1966,
  type = {{{MIT AI Memos}}},
  title = {The {{Summer Vision Project}}},
  abstract = {The summer vision project is an attempt to use our summer workers effectively in the construction of a significant part of a visual system. The particular task was chosen partly because it can be segmented into sub-problems which allow individuals to work independently and yet participate in the construction of a system complex enough to be real landmark in the development of "pattern recognition". The basic structure is fixed for the first phase of work extending to some point in July. Everyone is invited to contribute to the discussion of the second phase. Sussman is coordinator of "Vision Project" meetings and should be consulted by anyone who wishes to participate. The primary goal of the project is to construct a system of programs which will divide a vidisector picture into regions such as likely objects, likely background areas and chaos. We shall call this part of its operation FIGURE-GROUND analysis. It will be impossible to do this without considerable analysis of shape and surface properties, so FIGURE-GROUND analysis is really inseparable in practice from the second goal which is REGION DESCRIPTION. The final goal is OBJECT IDENTIFICATION which will actually name objects by matching them with a vocabulary of known objects.},
  number = {100},
  author = {Papert, Seymour},
  year = {1966}
}



@article{russakovsky_imagenet_2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  volume = {115},
  issn = {1573-1405},
  doi = {10.1007/s11263-015-0816-y},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
  language = {en},
  number = {3},
  journal = {International Journal of Computer Vision},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and {Fei-Fei}, Li},
  month = dec,
  year = {2015},
  keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
  pages = {211-252},
  file = {C:\\Users\\Owner\\Zotero\\storage\\V5JNXBBQ\\Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf}
}


