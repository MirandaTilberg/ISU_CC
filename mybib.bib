@article{ANNasModelsofNeuralInfoProcessing,
	title = {Editorial: {Artificial} {Neural} {Networks} as {Models} of {Neural} {Information} {Processing}},
	volume = {11},
	issn = {1662-5188},
	shorttitle = {Editorial},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2017.00114/full},
	doi = {10.3389/fncom.2017.00114},
	abstract = {Editorial: Artificial Neural Networks as Models of Neural Information Processing},
	language = {English},
	urldate = {2019-01-16},
	journal = {Frontiers in Computational Neuroscience},
	author = {Gerven, Marcel van and Bohte, Sander},
	year = {2017},
	keywords = {artificial intelligence, computational neuroscience, neural networks, rate coding, spiking neural networks},
	file = {Full Text PDF:C\:\\Users\\Owner\\Zotero\\storage\\HCYDPRQS\\van Gerven and Bohte - 2017 - Editorial Artificial Neural Networks as Models of.pdf:application/pdf}
}


@incollection{yosinskiHowTransferableAre2014,
	title = {How transferable are features in deep neural networks?},
	url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf},
	urldate = {2019-02-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	note = {02191},
	pages = {3320--3328},
	file = {NIPS Snapshot:/home/srvander/Zotero/storage/TUSQPF67/5347-how-transferable-are-features-in-deep-neural-networks.html:text/html;Yosinski et al_2014_How transferable are features in deep neural networks.pdf:/home/srvander/Zotero/storage/I53LNAP9/Yosinski et al_2014_How transferable are features in deep neural networks.pdf:application/pdf}
}

@article{grossVariabilitySignificanceClass2013,
  title = {The Variability and Significance of Class Characteristics in Footwear Impressions},
  volume = {63},
  number = {3},
  journal = {Journal of Forensic Identification},
  year = {2013},
  pages = {332},
  author = {Gross, Susan and Jeppesen, Dane and Neumann, Cedric},
  file = {/home/srvander/Zotero/storage/EC9IV5R5/Gross et al_2013_The variability and significance of class characteristics in footwear.pdf}
}

@article{hancockInterpretationShoeprintComparison2012,
  title = {The Interpretation of Shoeprint Comparison Class Correspondences},
  volume = {52},
  number = {4},
  journal = {Science and Justice},
  year = {2012},
  pages = {243--248},
  author = {Hancock, Sheida and Morgan-Smith, Rian and Buckleton, John},
  file = {/home/srvander/Zotero/storage/6ULEJZV5/Hancock et al_2012_The interpretation of shoeprint comparison class correspondences.pdf}
}

@inproceedings{pavlouAutomaticExtractionClassification2006,
  title = {Automatic Extraction and Classification of Footwear Patterns},
  booktitle = {International {{Conference}} on {{Intelligent Data Engineering}} and {{Automated Learning}}},
  publisher = {{Springer}},
  year = {2006},
  pages = {721--728},
  author = {Pavlou, Maria and Allinson, Nigel M},
  file = {/home/srvander/Zotero/storage/EBZL8VGE/Pavlou_Allinson_2006_Automatic extraction and classification of footwear patterns.pdf}
}


@article{vgg16,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {https://arxiv.org/abs/1409.1556},
	language = {en},
	urldate = {2018-10-16},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	file = {Simonyan_Zisserman_2014_Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:/home/srvander/Zotero/storage/ULPNXPMS/Simonyan_Zisserman_2014_Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:application/pdf;Snapshot:/home/srvander/Zotero/storage/XG4LXKA2/1409.html:text/html}
}
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{guRecentAdvancesConvolutional2018,
	title = {Recent advances in convolutional neural networks},
	volume = {77},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320317304120},
	doi = {10.1016/j.patcog.2017.10.013},
	abstract = {In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.},
	language = {en},
	urldate = {2019-02-18},
	journal = {Pattern Recognition},
	author = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
	month = may,
	year = {2018},
	pages = {354--377}
}

@book{mallot2000computational,
	title = {Computational {Vision}: {Information} {Processing} in {Perception} and {Visual} {Behaviour}},
	isbn = {978-0-262-13381-4},
	url = {https://books.google.com/books?id=LrGfKrmQbQoC},
	publisher = {Bradford book},
	author = {Mallot, H.A. and Allen, J.S. and Sejnowski, T.J.},
	year = {2000}
}


@article{geirhosComparingDeepNeural2017,
	title = {Comparing deep neural networks against humans: object recognition when the signal gets weaker},
	shorttitle = {Comparing deep neural networks against humans},
	url = {http://arxiv.org/abs/1706.06969},
	urldate = {2019-02-18},
	journal = {arXiv:1706.06969 [cs, q-bio, stat]},
	author = {Geirhos, Robert and Janssen, David H. J. and Sch√ºtt, Heiko H. and Rauber, Jonas and Bethge, Matthias and Wichmann, Felix A.},
	month = jun,
	year = {2017}
}

@article{LabelMe,
 author = {Russell, Bryan C. and Torralba, Antonio and Murphy, Kevin P. and Freeman, William T.},
 title = {LabelMe: A Database and Web-Based Tool for Image Annotation},
 journal = {Int. J. Comput. Vision},
 issue_date = {May       2008},
 volume = {77},
 number = {1-3},
 month = may,
 year = {2008},
 issn = {0920-5691},
 pages = {157--173},
 numpages = {17},
 url = {http://dx.doi.org/10.1007/s11263-007-0090-8},
 doi = {10.1007/s11263-007-0090-8},
 acmid = {1345999},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Annotation tool, Database, Object detection, Object recognition},
}


@techreport{papert_summer_1966,
  type = {{{MIT AI Memos}}},
  title = {The {{Summer Vision Project}}},
  abstract = {The summer vision project is an attempt to use our summer workers effectively in the construction of a significant part of a visual system. The particular task was chosen partly because it can be segmented into sub-problems which allow individuals to work independently and yet participate in the construction of a system complex enough to be real landmark in the development of "pattern recognition". The basic structure is fixed for the first phase of work extending to some point in July. Everyone is invited to contribute to the discussion of the second phase. Sussman is coordinator of "Vision Project" meetings and should be consulted by anyone who wishes to participate. The primary goal of the project is to construct a system of programs which will divide a vidisector picture into regions such as likely objects, likely background areas and chaos. We shall call this part of its operation FIGURE-GROUND analysis. It will be impossible to do this without considerable analysis of shape and surface properties, so FIGURE-GROUND analysis is really inseparable in practice from the second goal which is REGION DESCRIPTION. The final goal is OBJECT IDENTIFICATION which will actually name objects by matching them with a vocabulary of known objects.},
  number = {100},
  author = {Papert, Seymour},
  year = {1966}
}



@article{russakovsky_imagenet_2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  volume = {115},
  issn = {1573-1405},
  doi = {10.1007/s11263-015-0816-y},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
  language = {en},
  number = {3},
  journal = {International Journal of Computer Vision},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and {Fei-Fei}, Li},
  month = dec,
  year = {2015},
  keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
  pages = {211-252},
  file = {C:\\Users\\Owner\\Zotero\\storage\\V5JNXBBQ\\Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf}
}



@book{bodziak_footwear_2000,
	address = {Boca Raton, Florida},
	title = {Footwear {Impression} {Evidence}: {Detection}, {Recovery}, and {Examination}},
	isbn = {0-8493-1045-8},
	publisher = {CRC Press},
	author = {Bodziak, William J.},
	year = {2000},
	note = {00319},
	keywords = {iai\_recommended\_course\_of\_study\_2006}
}
